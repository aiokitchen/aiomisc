# Translations template for aiomisc.
# Copyright (C) 2021
# This file is distributed under the same license as the aiomisc project.
# Dmitry Orlov <me@mosquito.su>, 2022.
msgid ""
msgstr ""
"Project-Id-Version:  14\n"
"Report-Msgid-Bugs-To: me@mosquito.su\n"
"POT-Creation-Date: 2022-12-29 11:36+0300\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Dmitry Orlov <me@mosquito.su>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../../source/threads.rst:2
msgid "Working with threads"
msgstr "Работа с потоками"

#: ../../source/threads.rst:4
msgid "Wraps blocking function and run it in the different thread or thread pool."
msgstr ""
"Можно обернуть блокирующую функцию и запустить ее в отдельном потоке или "
"пуле потоков."

#: ../../source/threads.rst:8
msgid "``contextvars`` support"
msgstr "Поддержка ``contextvars``"

#: ../../source/threads.rst:10
msgid ""
"All following decorators and functions support ``contextvars`` module, "
"from PyPI for python earlier 3.7 and builtin a standard library for "
"python 3.7."
msgstr ""
"Все нижеописанные декоратоы и функции поддерживают модуль "
"``contextvars``, из PyPI для python моложе 3.7 так и встроенный в "
"стандартную библиотеку модуль для python 3.7."

#: ../../source/threads.rst:13
msgid ""
"import asyncio\n"
"import aiomisc\n"
"import contextvars\n"
"import random\n"
"import struct\n"
"\n"
"\n"
"user_id = contextvars.ContextVar(\"user_id\")\n"
"\n"
"record_struct = struct.Struct(\">I\")\n"
"\n"
"\n"
"@aiomisc.threaded\n"
"def write_user():\n"
"    with open(\"/tmp/audit.bin\", 'ab') as fp:\n"
"        fp.write(record_struct.pack(user_id.get()))\n"
"\n"
"\n"
"@aiomisc.threaded\n"
"def read_log():\n"
"    with open(\"/tmp/audit.bin\", \"rb\") as fp:\n"
"        for chunk in iter(lambda: fp.read(record_struct.size), b''):\n"
"            yield record_struct.unpack(chunk)[0]\n"
"\n"
"\n"
"async def main():\n"
"    futures = []\n"
"    for _ in range(5):\n"
"        user_id.set(random.randint(1, 65535))\n"
"        futures.append(write_user())\n"
"\n"
"    await asyncio.gather(*futures)\n"
"\n"
"    async for data in read_log():\n"
"        print(data)\n"
"\n"
"\n"
"if __name__ == '__main__':\n"
"    with aiomisc.entrypoint() as loop:\n"
"        loop.run_until_complete(main())"
msgstr ""

#: ../../source/threads.rst:57
msgid "Example output:"
msgstr "Пример вывода"

#: ../../source/threads.rst:59
msgid ""
"6621\n"
"33012\n"
"1590\n"
"45008\n"
"56844"
msgstr ""

#: ../../source/threads.rst:70
msgid ""
"``contextvars`` has different use cases then ``Context`` class. "
"``contextvars``are applicable for passing context variables through the "
"execution stack but created task can not change parent context variables "
"because ``contextvars``create lightweight copy. ``Context`` class allows "
"it because does not copy context variables."
msgstr ""
"``contextvars`` нужны для другого случая нежели класс ``Context``. "
"``contextvars`` хорошо применимы для передачи контекстных переменных "
"сквозь стек вызовов, однако дочерние задачи не смогут модифицировать "
"контекстные переменные родительских задач потому, что ``contextvars`` "
"делает их \"легкие копии\" перед запуском новой задачи. Класс ``Context``"
" наоборот позволяет модификацию отовсюду так как не копирует ничего."

#: ../../source/threads.rst:78
msgid "``@aiomisc.threaded``"
msgstr ""

#: ../../source/threads.rst:80
msgid "Wraps blocking function and run it in the current thread pool."
msgstr "Оборачивает блокирующую функцию и запускает ее в пуле потоков."

#: ../../source/threads.rst:83
msgid ""
"import asyncio\n"
"import time\n"
"from aiomisc import new_event_loop, threaded\n"
"\n"
"\n"
"@threaded\n"
"def blocking_function():\n"
"    time.sleep(1)\n"
"\n"
"\n"
"async def main():\n"
"    # Running in parallel\n"
"    await asyncio.gather(\n"
"        blocking_function(),\n"
"        blocking_function(),\n"
"    )\n"
"\n"
"\n"
"if __name__ == '__main__':\n"
"    loop = new_event_loop()\n"
"    loop.run_until_complete(main())"
msgstr ""
"import asyncio\n"
"import time\n"
"from aiomisc import new_event_loop, threaded\n"
"\n"
"\n"
"@threaded\n"
"def blocking_function():\n"
"    time.sleep(1)\n"
"\n"
"\n"
"async def main():\n"
"    # Параллельный запуск\n"
"    await asyncio.gather(\n"
"        blocking_function(),\n"
"        blocking_function(),\n"
"    )\n"
"\n"
"\n"
"if __name__ == '__main__':\n"
"    loop = new_event_loop()\n"
"    loop.run_until_complete(main())"

#: ../../source/threads.rst:107
msgid ""
"In case the function is a generator function ``@threaded`` decorator will"
" return ``IteratorWrapper`` (see Threaded generator decorator)."
msgstr ""
"В случае если функция это генератор тогда декоратор ``@threaded`` вернет "
"``IteratorWrapper`` (см Threaded generator decorator)."

#: ../../source/threads.rst:112
msgid "``@aiomisc.threaded_separate``"
msgstr ""

#: ../../source/threads.rst:114
msgid ""
"Wraps blocking function and run it in a new separate thread. Highly "
"recommended for long background tasks:"
msgstr ""
"Оборачивает блокирующую функцию и запускает ее в отдельном новом "
"потоке.Крайне рекомендовано для длительных фоновых задач:"

#: ../../source/threads.rst:117
msgid ""
"import asyncio\n"
"import time\n"
"import threading\n"
"import aiomisc\n"
"\n"
"\n"
"@aiomisc.threaded\n"
"def blocking_function():\n"
"    time.sleep(1)\n"
"\n"
"\n"
"@aiomisc.threaded_separate\n"
"def long_blocking_function(event: threading.Event):\n"
"    while not event.is_set():\n"
"        print(\"Running\")\n"
"        time.sleep(1)\n"
"    print(\"Exitting\")\n"
"\n"
"\n"
"async def main():\n"
"    stop_event = threading.Event()\n"
"\n"
"    loop = asyncio.get_event_loop()\n"
"    loop.call_later(10, stop_event.set)\n"
"\n"
"    # Running in parallel\n"
"    await asyncio.gather(\n"
"        blocking_function(),\n"
"        # New thread will be spawned\n"
"        long_blocking_function(stop_event),\n"
"    )\n"
"\n"
"\n"
"with aiomisc.entrypoint() as loop:\n"
"    loop.run_until_complete(main())"
msgstr ""
"import asyncio\n"
"import time\n"
"import threading\n"
"import aiomisc\n"
"\n"
"\n"
"@aiomisc.threaded\n"
"def blocking_function():\n"
"    time.sleep(1)\n"
"\n"
"\n"
"@aiomisc.threaded_separate\n"
"def long_blocking_function(event: threading.Event):\n"
"    while not event.is_set():\n"
"        print(\"Running\")\n"
"        time.sleep(1)\n"
"    print(\"Выходим\")\n"
"\n"
"\n"
"async def main():\n"
"    stop_event = threading.Event()\n"
"\n"
"    loop = asyncio.get_event_loop()\n"
"    loop.call_later(10, stop_event.set)\n"
"\n"
"    # Параллельный запуск\n"
"    await asyncio.gather(\n"
"        blocking_function(),\n"
"        # Будет запущен отдельный новый поток\n"
"        long_blocking_function(stop_event),\n"
"    )\n"
"\n"
"\n"
"with aiomisc.entrypoint() as loop:\n"
"    loop.run_until_complete(main())"

#: ../../source/threads.rst:157
msgid "Threaded iterator decorator"
msgstr "Threaded iterator decorator"

#: ../../source/threads.rst:159
msgid ""
"Wraps blocking generator function and run it in the current thread pool "
"or on a new separate thread."
msgstr ""
"Оборачивает блокирующую функцию-генератор и запусакет ее в текущем пуле "
"потоков или новом отдельном потоке."

#: ../../source/threads.rst:162
msgid ""
"Following example reads itself file, chains hashes of every line with the"
" hash of the previous line and sends hash and content via TCP:"
msgstr ""
"Следующий пример читает свой собственный код, и обновляет хеш для каждой "
"следующей строки от предидущих строк, и отправляет все это по TCP:"

#: ../../source/threads.rst:165
msgid ""
"import asyncio\n"
"import hashlib\n"
"\n"
"import aiomisc\n"
"\n"
"# My first blockchain\n"
"\n"
"@aiomisc.threaded_iterable\n"
"def blocking_reader(fname):\n"
"    with open(fname, \"r+\") as fp:\n"
"        md5_hash = hashlib.md5()\n"
"        for line in fp:\n"
"            bytes_line = line.encode()\n"
"            md5_hash.update(bytes_line)\n"
"            yield bytes_line, md5_hash.hexdigest().encode()\n"
"\n"
"\n"
"async def main():\n"
"    reader, writer = await asyncio.open_connection(\"127.0.0.1\", 2233)\n"
"    async with blocking_reader(__file__) as gen:\n"
"        async for line, digest in gen:\n"
"            writer.write(digest)\n"
"            writer.write(b'\\t')\n"
"            writer.write(line)\n"
"            await writer.drain()\n"
"\n"
"\n"
"with aiomisc.entrypoint() as loop\n"
"    loop.run_until_complete(main())"
msgstr ""
"import asyncio\n"
"import hashlib\n"
"\n"
"import aiomisc\n"
"\n"
"# Мой первый блокчейн\n"
"\n"
"@aiomisc.threaded_iterable\n"
"def blocking_reader(fname):\n"
"    with open(fname, \"r+\") as fp:\n"
"        md5_hash = hashlib.md5()\n"
"        for line in fp:\n"
"            bytes_line = line.encode()\n"
"            md5_hash.update(bytes_line)\n"
"            yield bytes_line, md5_hash.hexdigest().encode()\n"
"\n"
"\n"
"async def main():\n"
"    reader, writer = await asyncio.open_connection(\"127.0.0.1\", 2233)\n"
"    async with blocking_reader(__file__) as gen:\n"
"        async for line, digest in gen:\n"
"            writer.write(digest)\n"
"            writer.write(b'\\t')\n"
"            writer.write(line)\n"
"            await writer.drain()\n"
"\n"
"\n"
"with aiomisc.entrypoint() as loop\n"
"    loop.run_until_complete(main())"

#: ../../source/threads.rst:199
msgid "Run ``netcat`` listener in the terminal and run this example"
msgstr ""
"Запустим TCP сервер с помощью ``netcat`` в терминале, и после запустим "
"этот пример."

#: ../../source/threads.rst:201
msgid ""
"$ netcat -v -l -p 2233\n"
"Connection from 127.0.0.1:54734\n"
"dc80feba2326979f8976e387fbbc8121   import asyncio\n"
"78ec3bcb1c441614ede4af5e5b28f638   import hashlib\n"
"b7df4a0a4eac401b2f835447e5fc4139\n"
"f0a94eb3d7ad23d96846c8cb5e327454   import aiomisc\n"
"0c05dde8ac593bad97235e6ae410cb58\n"
"e4d639552b78adea6b7c928c5ebe2b67   # My first blockchain\n"
"5f04aef64f4cacce39170142fe45e53e\n"
"c0019130ba5210b15db378caf7e9f1c9   @aiomisc.threaded_iterable\n"
"a720db7e706d10f55431a921cdc1cd4c   def blocking_reader(fname):\n"
"0895d7ca2984ea23228b7d653d0b38f2       with open(fname, \"r+\") as fp:\n"
"0feca8542916af0b130b2d68ade679cf           md5_hash = hashlib.md5()\n"
"4a9ddfea3a0344cadd7a80a8b99ff85c           for line in fp:\n"
"f66fa1df3d60b7ac8991244455dff4ee               bytes_line = line.encode()"
"\n"
"aaac23a5aa34e0f5c448a8d7e973f036               "
"md5_hash.update(bytes_line)\n"
"2040bcaab6137b60e51ae6bd1e279546               yield bytes_line, "
"md5_hash.hexdigest().encode()\n"
"7346740fdcde6f07d42ecd2d6841d483\n"
"14dfb2bae89fa0d7f9b6cba2b39122c4\n"
"d69cc5fe0779f0fa800c6ec0e2a7cbbd   async def main():\n"
"ead8ef1571e6b4727dcd9096a3ade4da       reader, writer = await "
"asyncio.open_connection(\"127.0.0.1\", 2233)\n"
"275eb71a6b6fb219feaa5dc2391f47b7       async with "
"blocking_reader(__file__) as gen:\n"
"110375ba7e8ab3716fd38a6ae8ec8b83           async for line, digest in gen:"
"\n"
"c26894b38440dbdc31f77765f014f445               writer.write(digest)\n"
"27659596bd880c55e2bc72b331dea948               writer.write(b'\\t')\n"
"8bb9e27b43a9983c9621c6c5139a822e               writer.write(line)\n"
"2659fbe434899fc66153decf126fdb1c               await writer.drain()\n"
"6815f69821da8e1fad1d60ac44ef501e\n"
"5acc73f7a490dcc3b805e75fb2534254\n"
"0f29ad9505d1f5e205b0cbfef572ab0e   if __name__ == '__main__':\n"
"8b04db9d80d8cda79c3b9c4640c08928       loop = aiomisc.new_event_loop()\n"
"9cc5f29f81e15cb262a46cf96b8788ba       loop.run_until_complete(main())"
msgstr ""
"$ netcat -v -l -p 2233\n"
"Connection from 127.0.0.1:54734\n"
"dc80feba2326979f8976e387fbbc8121   import asyncio\n"
"78ec3bcb1c441614ede4af5e5b28f638   import hashlib\n"
"b7df4a0a4eac401b2f835447e5fc4139\n"
"f0a94eb3d7ad23d96846c8cb5e327454   import aiomisc\n"
"0c05dde8ac593bad97235e6ae410cb58\n"
"e4d639552b78adea6b7c928c5ebe2b67   # Мой первый блокчейн\n"
"5f04aef64f4cacce39170142fe45e53e\n"
"c0019130ba5210b15db378caf7e9f1c9   @aiomisc.threaded_iterable\n"
"a720db7e706d10f55431a921cdc1cd4c   def blocking_reader(fname):\n"
"0895d7ca2984ea23228b7d653d0b38f2       with open(fname, \"r+\") as fp:\n"
"0feca8542916af0b130b2d68ade679cf           md5_hash = hashlib.md5()\n"
"4a9ddfea3a0344cadd7a80a8b99ff85c           for line in fp:\n"
"f66fa1df3d60b7ac8991244455dff4ee               bytes_line = line.encode()"
"\n"
"aaac23a5aa34e0f5c448a8d7e973f036               "
"md5_hash.update(bytes_line)\n"
"2040bcaab6137b60e51ae6bd1e279546               yield bytes_line, "
"md5_hash.hexdigest().encode()\n"
"7346740fdcde6f07d42ecd2d6841d483\n"
"14dfb2bae89fa0d7f9b6cba2b39122c4\n"
"d69cc5fe0779f0fa800c6ec0e2a7cbbd   async def main():\n"
"ead8ef1571e6b4727dcd9096a3ade4da       reader, writer = await "
"asyncio.open_connection(\"127.0.0.1\", 2233)\n"
"275eb71a6b6fb219feaa5dc2391f47b7       async with "
"blocking_reader(__file__) as gen:\n"
"110375ba7e8ab3716fd38a6ae8ec8b83           async for line, digest in gen:"
"\n"
"c26894b38440dbdc31f77765f014f445               writer.write(digest)\n"
"27659596bd880c55e2bc72b331dea948               writer.write(b'\\t')\n"
"8bb9e27b43a9983c9621c6c5139a822e               writer.write(line)\n"
"2659fbe434899fc66153decf126fdb1c               await writer.drain()\n"
"6815f69821da8e1fad1d60ac44ef501e\n"
"5acc73f7a490dcc3b805e75fb2534254\n"
"0f29ad9505d1f5e205b0cbfef572ab0e   if __name__ == '__main__':\n"
"8b04db9d80d8cda79c3b9c4640c08928       loop = aiomisc.new_event_loop()\n"
"9cc5f29f81e15cb262a46cf96b8788ba       loop.run_until_complete(main())"

#: ../../source/threads.rst:237
msgid ""
"You should use async context managers in the case when your generator "
"works infinity, or you have to await the ``.close()`` method when you "
"avoid context managers."
msgstr ""
"Придется использовать асинхронный контекст-менеджер в случае если "
"генератор бесконечный или придется явно вызвать и дождаться метода "
"``.close()`` если вы избегаете использование асинхронных "
"контекст-менеджеров."

#: ../../source/threads.rst:240
msgid ""
"import asyncio\n"
"import aiomisc\n"
"\n"
"\n"
"# Set 2 chunk buffer\n"
"@aiomisc.threaded_iterable(max_size=2)\n"
"def urandom_reader():\n"
"    with open('/dev/urandom', \"rb\") as fp:\n"
"        while True:\n"
"            yield fp.read(8)\n"
"\n"
"\n"
"# Infinity buffer on a separate thread\n"
"@aiomisc.threaded_iterable_separate\n"
"def blocking_reader(fname):\n"
"    with open(fname, \"r\") as fp:\n"
"        yield from fp\n"
"\n"
"\n"
"async def main():\n"
"    reader, writer = await asyncio.open_connection(\"127.0.0.1\", 2233)\n"
"    async for line in blocking_reader(__file__):\n"
"        writer.write(line.encode())\n"
"\n"
"    await writer.drain()\n"
"\n"
"    # Feed white noise\n"
"    gen = urandom_reader()\n"
"    counter = 0\n"
"    async for line in gen:\n"
"        writer.write(line)\n"
"        counter += 1\n"
"\n"
"        if counter == 10:\n"
"            break\n"
"\n"
"    await writer.drain()\n"
"\n"
"    # Stop running generator\n"
"    await gen.close()\n"
"\n"
"    # Using context manager\n"
"    async with urandom_reader() as gen:\n"
"        counter = 0\n"
"        async for line in gen:\n"
"            writer.write(line)\n"
"            counter += 1\n"
"\n"
"            if counter == 10:\n"
"                break\n"
"\n"
"    await writer.drain()\n"
"\n"
"\n"
"with aiomisc.entrypoint() as loop:\n"
"    loop.run_until_complete(main())"
msgstr ""
"import asyncio\n"
"import aiomisc\n"
"\n"
"\n"
"# Настраиваем буфер на 2 элемента вперед\n"
"@aiomisc.threaded_iterable(max_size=2)\n"
"def urandom_reader():\n"
"    with open('/dev/urandom', \"rb\") as fp:\n"
"        while True:\n"
"            yield fp.read(8)\n"
"\n"
"\n"
"# Бесконечный буфер в отдельном потоке\n"
"@aiomisc.threaded_iterable_separate\n"
"def blocking_reader(fname):\n"
"    with open(fname, \"r\") as fp:\n"
"        yield from fp\n"
"\n"
"\n"
"async def main():\n"
"    reader, writer = await asyncio.open_connection(\"127.0.0.1\", 2233)\n"
"    async for line in blocking_reader(__file__):\n"
"        writer.write(line.encode())\n"
"\n"
"    await writer.drain()\n"
"\n"
"    # Будем \"кушать\" белый шум\n"
"    gen = urandom_reader()\n"
"    counter = 0\n"
"    async for line in gen:\n"
"        writer.write(line)\n"
"        counter += 1\n"
"\n"
"        if counter == 10:\n"
"            break\n"
"\n"
"    await writer.drain()\n"
"\n"
"    # Останавливаем запущенный генератор\n"
"    await gen.close()\n"
"\n"
"    # Тоже самое, только через контекст менеджер\n"
"    async with urandom_reader() as gen:\n"
"        counter = 0\n"
"        async for line in gen:\n"
"            writer.write(line)\n"
"            counter += 1\n"
"\n"
"            if counter == 10:\n"
"                break\n"
"\n"
"    await writer.drain()\n"
"\n"
"\n"
"with aiomisc.entrypoint() as loop:\n"
"    loop.run_until_complete(main())"

#: ../../source/threads.rst:300
msgid "``aiomisc.IteratorWrapper``"
msgstr ""

#: ../../source/threads.rst:302
msgid "Run iterables on dedicated thread pool:"
msgstr "Запускает блокирующий итератор в пуле потоков:"

#: ../../source/threads.rst:304
msgid ""
"import concurrent.futures\n"
"import hashlib\n"
"import aiomisc\n"
"\n"
"\n"
"def urandom_reader():\n"
"    with open('/dev/urandom', \"rb\") as fp:\n"
"        while True:\n"
"            yield fp.read(1024)\n"
"\n"
"\n"
"async def main():\n"
"    # create a new thread pool\n"
"    pool = concurrent.futures.ThreadPoolExecutor(1)\n"
"    wrapper = aiomisc.IteratorWrapper(\n"
"        urandom_reader,\n"
"        executor=pool,\n"
"        max_size=2\n"
"    )\n"
"\n"
"    async with wrapper as gen:\n"
"        md5_hash = hashlib.md5(b'')\n"
"        counter = 0\n"
"        async for item in gen:\n"
"            md5_hash.update(item)\n"
"            counter += 1\n"
"\n"
"            if counter >= 100:\n"
"                break\n"
"\n"
"    pool.shutdown()\n"
"    print(md5_hash.hexdigest())\n"
"\n"
"\n"
"if __name__ == '__main__':\n"
"    with aiomisc.entrypoint() as loop:\n"
"        loop.run_until_complete(main())"
msgstr ""
"import concurrent.futures\n"
"import hashlib\n"
"import aiomisc\n"
"\n"
"\n"
"def urandom_reader():\n"
"    with open('/dev/urandom', \"rb\") as fp:\n"
"        while True:\n"
"            yield fp.read(1024)\n"
"\n"
"\n"
"async def main():\n"
"    # Создаем новый пул потоков\n"
"    pool = concurrent.futures.ThreadPoolExecutor(1)\n"
"    wrapper = aiomisc.IteratorWrapper(\n"
"        urandom_reader,\n"
"        executor=pool,\n"
"        max_size=2\n"
"    )\n"
"\n"
"    async with wrapper as gen:\n"
"        md5_hash = hashlib.md5(b'')\n"
"        counter = 0\n"
"        async for item in gen:\n"
"            md5_hash.update(item)\n"
"            counter += 1\n"
"\n"
"            if counter >= 100:\n"
"                break\n"
"\n"
"    pool.shutdown()\n"
"    print(md5_hash.hexdigest())\n"
"\n"
"\n"
"if __name__ == '__main__':\n"
"    with aiomisc.entrypoint() as loop:\n"
"        loop.run_until_complete(main())"

#: ../../source/threads.rst:345
msgid "``aiomisc.IteratorWrapperSeparate``"
msgstr ""

#: ../../source/threads.rst:347
msgid "Run iterables on a separate thread:"
msgstr "Запускает блокирующий итераторы в отдельном новом потоке:"

#: ../../source/threads.rst:349
msgid ""
"import concurrent.futures\n"
"import hashlib\n"
"import aiomisc\n"
"\n"
"\n"
"def urandom_reader():\n"
"    with open('/dev/urandom', \"rb\") as fp:\n"
"        while True:\n"
"            yield fp.read(1024)\n"
"\n"
"\n"
"async def main():\n"
"    # create a new thread pool\n"
"    wrapper = aiomisc.IteratorWrapperSeparate(\n"
"        urandom_reader, max_size=2\n"
"    )\n"
"\n"
"    async with wrapper as gen:\n"
"        md5_hash = hashlib.md5(b'')\n"
"        counter = 0\n"
"        async for item in gen:\n"
"            md5_hash.update(item)\n"
"            counter += 1\n"
"\n"
"            if counter >= 100:\n"
"                break\n"
"\n"
"    print(md5_hash.hexdigest())\n"
"\n"
"\n"
"if __name__ == '__main__':\n"
"    with aiomisc.entrypoint() as loop:\n"
"        loop.run_until_complete(main())"
msgstr ""
"import concurrent.futures\n"
"import hashlib\n"
"import aiomisc\n"
"\n"
"\n"
"def urandom_reader():\n"
"    with open('/dev/urandom', \"rb\") as fp:\n"
"        while True:\n"
"            yield fp.read(1024)\n"
"\n"
"\n"
"async def main():\n"
"    # Создаем новый пул потоков\n"
"    wrapper = aiomisc.IteratorWrapperSeparate(\n"
"        urandom_reader, max_size=2\n"
"    )\n"
"\n"
"    async with wrapper as gen:\n"
"        md5_hash = hashlib.md5(b'')\n"
"        counter = 0\n"
"        async for item in gen:\n"
"            md5_hash.update(item)\n"
"            counter += 1\n"
"\n"
"            if counter >= 100:\n"
"                break\n"
"\n"
"    print(md5_hash.hexdigest())\n"
"\n"
"\n"
"if __name__ == '__main__':\n"
"    with aiomisc.entrypoint() as loop:\n"
"        loop.run_until_complete(main())"

#: ../../source/threads.rst:388
msgid "``aiomisc.ThreadPoolExecutor``"
msgstr ""

#: ../../source/threads.rst:390
msgid "This is a fast thread pool implementation."
msgstr "Реализация быстрого и простого пула потоков."

#: ../../source/threads.rst:392
msgid "Setting as a default thread pool:"
msgstr "Устанавливаем как пул потоков по умолчанию:"

#: ../../source/threads.rst:394
msgid ""
"import asyncio\n"
"from aiomisc import ThreadPoolExecutor\n"
"\n"
"loop = asyncio.get_event_loop()\n"
"thread_pool = ThreadPoolExecutor(4)\n"
"loop.set_default_executor(thread_pool)"
msgstr ""

#: ../../source/threads.rst:406
msgid "``entrypoint`` context manager will set it by default."
msgstr "``entrypoint`` установит это по умолчанию."

#: ../../source/threads.rst:408
msgid "``entrypoint``'s argument ``pool_size`` limits thread pool size."
msgstr ""
"Аргумент ``pool_size`` в ``entrypoint`` ограничивает кол-во потоков п "
"пуле."

#: ../../source/threads.rst:412
msgid "``aiomisc.sync_wait_coroutine``"
msgstr ""

#: ../../source/threads.rst:414
msgid ""
"Functions running in thread can't call and wait for a result from "
"coroutines by default. This function is the helper for send coroutine to "
"the event loop and waits for it in the current thread."
msgstr ""
"Функции запущенные в потоке не могут вызывать и дожидаться сопрограмм по "
"умолчанию. Эта функция это хелпер позволяет отправить сопрограмму в event"
" loop и дождаться ее результата из текущего потока."

#: ../../source/threads.rst:418
msgid ""
"import asyncio\n"
"import aiomisc\n"
"\n"
"\n"
"async def coro():\n"
"    print(\"Coroutine started\")\n"
"    await asyncio.sleep(1)\n"
"    print(\"Coroutine done\")\n"
"\n"
"\n"
"@aiomisc.threaded\n"
"def in_thread(loop):\n"
"    print(\"Thread started\")\n"
"    aiomisc.sync_wait_coroutine(loop, coro)\n"
"    print(\"Thread finished\")\n"
"\n"
"\n"
"with aiomisc.entrypoint() as loop:\n"
"    loop.run_until_complete(in_thread(loop))"
msgstr ""
