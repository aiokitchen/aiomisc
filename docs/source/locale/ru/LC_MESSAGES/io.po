# Translations template for aiomisc.
# Copyright (C) 2021
# This file is distributed under the same license as the aiomisc project.
# Dmitry Orlov <me@mosquito.su>, 2022.
msgid ""
msgstr ""
"Project-Id-Version:  14\n"
"Report-Msgid-Bugs-To: me@mosquito.su\n"
"POT-Creation-Date: 2023-02-02 17:01+0300\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: Dmitry Orlov <me@mosquito.su>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../../source/io.rst:2
msgid "asynchronous file operations"
msgstr "асинхронные операции с файлами"

#: ../../source/io.rst:4
msgid ""
"Asynchronous files operations including support for data compression on "
"the fly. Based on the thread pool under the hood."
msgstr ""
"Асинхронные файловые операции, включая поточную компрессию данных. "
"Работают в пуле потоков \"под капотом\"."

#: ../../source/io.rst:7
msgid ""
"import aiomisc\n"
"import tempfile\n"
"from pathlib import Path\n"
"\n"
"\n"
"async def file_write():\n"
"    with tempfile.TemporaryDirectory() as tmp:\n"
"        fname = Path(tmp) / 'test.txt'\n"
"\n"
"        # Some tools, such as mypy, will not be able to infer the type\n"
"        # from the `async_open` function based on the `b` character "
"passed\n"
"        # to the mode.\n"
"        # We'll have to tell the type here explicitly.\n"
"        afp: aiomisc.io.AsyncTextIO\n"
"\n"
"        async with aiomisc.io.async_open(fname, 'w+') as afp:\n"
"            await afp.write(\"Hello\")\n"
"            await afp.write(\" \")\n"
"            await afp.write(\"world\")\n"
"\n"
"            await afp.seek(0)\n"
"            print(await afp.read())\n"
"\n"
"\n"
"with aiomisc.entrypoint() as loop:\n"
"    loop.run_until_complete(file_write())"
msgstr ""
"import aiomisc\n"
"import tempfile\n"
"from pathlib import Path\n"
"\n"
"\n"
"async def file_write():\n"
"    with tempfile.TemporaryDirectory() as tmp:\n"
"        fname = Path(tmp) / 'test.txt'\n"
"\n"
"        # Некоторые инструменты, такие как mypy, не смогут вывести тип \n"
"        # из функции async_open основываясь на переданном символе `b` в "
"режим.\n"
"        # Придется тут подсказать тип явно.\n"
"        afp: aiomisc.io.AsyncTextIO\n"
"\n"
"        async with aiomisc.io.async_open(fname, 'w+') as afp:\n"
"            await afp.write(\"Hello\")\n"
"            await afp.write(\" \")\n"
"            await afp.write(\"world\")\n"
"\n"
"            await afp.seek(0)\n"
"            print(await afp.read())\n"
"\n"
"\n"
"with aiomisc.entrypoint() as loop:\n"
"    loop.run_until_complete(file_write())"

#: ../../source/io.rst:38
msgid ""
"This is the way to working with files based on threads. It's very similar"
" to `aiofiles`_ project and same limitations."
msgstr ""
"Этот способ работы с файлами основан на потоках. Это очень похоже на то "
"как сделано в библиотеке `aiofiles`_ с теми-же ограничениями."

#: ../../source/io.rst:41
msgid ""
"Of course, you can use `aiofile`_ project for this. But it's not a silver"
" bullet and has OS API-related limitations."
msgstr ""
"Разумеется вы можете использовать библиотеку `aiofile`_ для этого. Но это"
" не панацея, так как имеет ограничения связанные с API операционной "
"системы."

#: ../../source/io.rst:44
msgid ""
"In general, for light loads, I would advise you to adhere to the "
"following rules:"
msgstr ""
"В основном, для небольших нагрузок приложений, я рекомендую "
"придерживаться следующих правил:"

#: ../../source/io.rst:46
msgid ""
"If reading and writing small or big chunks from files with random access "
"is the main task in your project, use `aiofile`_."
msgstr ""
"Если чтение и запись маленьких или больших кусочков в файлы со случайным "
"доступом основная задача приложения - стоит использовать `aiofile`_."

#: ../../source/io.rst:48
msgid "Otherwise use this module or `aiofiles`_"
msgstr "Иначе можно взять этот модуль или `aiofiles`_"

#: ../../source/io.rst:49
msgid ""
"If the main task is to read large chunks of files for processing, both of"
" the above methods are not optimal cause you will switch context each IO "
"operation, it's often suboptimal for file cache and you will be lost "
"execution time for context switches. In case for thread-based IO executor"
" implementation thread context switches cost might be more expensive than"
" IO operation time in summary."
msgstr ""
"Если основная задача читать большие куски файлов для дальнейшей их "
"обработки оба вышеописанных метода будут не оптимальны, так как "
"переключения контекста каждую IO операцию - это скорее всего не будет "
"оптимально для файлового кеша и можно потерять бóльшую часть времени "
"исполнения на переключение контекста исполнения. В случае имплементации "
"асинхронного IO на основе потоков цена переключения контектса между "
"потоками может оказаться выше чем суммарно время исполнения всех IO "
"операций."

#: ../../source/io.rst:57
msgid ""
"Just try pack all blocking staff in separate functions and call it in a "
"thread pool, see the example bellow:"
msgstr ""
"Просто попробуйте завернуть все блокирующие вызовы в отдельные функции и "
"вызывайте их используя пул потоков (см. пример ниже):"

#: ../../source/io.rst:60
msgid ""
"import os\n"
"import aiomisc\n"
"import hashlib\n"
"import tempfile\n"
"from pathlib import Path\n"
"\n"
"\n"
"@aiomisc.threaded\n"
"def hash_file(filename, chunk_size=65535, hash_func=hashlib.blake2b):\n"
"    hasher = hash_func()\n"
"\n"
"    with open(filename, \"rb\") as fp:\n"
"        for chunk in iter(lambda: fp.read(chunk_size), b\"\"):\n"
"           hasher.update(chunk)\n"
"\n"
"    return hasher.hexdigest()\n"
"\n"
"\n"
"@aiomisc.threaded\n"
"def fill_random_file(filename, size, chunk_size=65535):\n"
"    with open(filename, \"wb\") as fp:\n"
"       while fp.tell() < size:\n"
"           fp.write(os.urandom(chunk_size))\n"
"\n"
"       return fp.tell()\n"
"\n"
"\n"
"async def main(path):\n"
"    filename = path / \"one\"\n"
"    await fill_random_file(filename, 1024 * 1024)\n"
"    first_hash = await hash_file(filename)\n"
"\n"
"    filename = path / \"two\"\n"
"    await fill_random_file(filename, 1024 * 1024)\n"
"    second_hash = await hash_file(filename)\n"
"\n"
"    assert first_hash != second_hash\n"
"\n"
"\n"
"with tempfile.TemporaryDirectory(prefix=\"random.\") as path:\n"
"   aiomisc.run(\n"
"       main(Path(path))\n"
"   )"
msgstr ""

#: ../../source/io.rst:108
msgid "In the fly compression"
msgstr "Поточное сжатие"

#: ../../source/io.rst:110
msgid ""
"To enable compression, you need to pass the `compression` argument to the"
" `async_open` function."
msgstr ""
"Чтобы включить поточное сжатие, нужно передать аргумент `compression` в "
"функцию `async_open`."

#: ../../source/io.rst:113
msgid "Supported compressors:"
msgstr "Поддерживаемые алгоритмы сжатия:"

#: ../../source/io.rst:115
msgid ":class:`aiomisc.io.Compression.NONE`"
msgstr ""

#: ../../source/io.rst:116
msgid ":class:`aiomisc.io.Compression.GZIP`"
msgstr ""

#: ../../source/io.rst:117
msgid ":class:`aiomisc.io.Compression.BZ2`"
msgstr ""

#: ../../source/io.rst:118
msgid ":class:`aiomisc.io.Compression.LZMA`"
msgstr ""

#: ../../source/io.rst:120
msgid "An example of usage:"
msgstr "Пример использования"

#: ../../source/io.rst:122
msgid ""
"import tempfile\n"
"from aiomisc import run\n"
"from aiomisc.io import async_open, Compression\n"
"from pathlib import Path\n"
"\n"
"\n"
"async def file_write():\n"
"    with tempfile.TemporaryDirectory() as tmp:\n"
"        fname = Path(tmp) / 'test.txt'\n"
"\n"
"        async with async_open(\n"
"            fname, 'w+', compression=Compression.GZIP\n"
"        ) as afp:\n"
"            for _ in range(10000):\n"
"                await afp.write(\"Hello World\\n\")\n"
"\n"
"        file_size = fname.stat().st_size\n"
"        assert file_size < 10000, f\"File too large {file_size} bytes\"\n"
"\n"
"run(file_write())"
msgstr ""
